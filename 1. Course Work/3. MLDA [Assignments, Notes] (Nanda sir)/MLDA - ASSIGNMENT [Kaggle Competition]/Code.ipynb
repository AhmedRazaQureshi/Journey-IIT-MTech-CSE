{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIOJrSlud3AU"
      },
      "source": [
        "# Home Work Assignment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1zKdznUayoZ"
      },
      "source": [
        "**This is a group assignment.**\n",
        "\n",
        "**Your home work assignment group will be same as your Kaggle group.**\n",
        "\n",
        "**Team lead must submit answers to TA Arabinda Panda by mail.**\n",
        "\n",
        "**There will be only one submission for a group**\n",
        "\n",
        "**Use your group name for naming the file, e.g, HW_1_GRP12**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6YsgQ1teI2K"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzkKad4WeRTK"
      },
      "source": [
        "Question1: Load data CIFAR10 from tensorflow keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEqKpE2XcDsa",
        "outputId": "d1228877-7662-4dc3-dde2-159b4b73c886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 12s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(trainX, trainY), (testX, testY) = tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDeISLodefEP"
      },
      "source": [
        "Question2: Split data into 80% train and 20% test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ok8dYVPacMgh"
      },
      "outputs": [],
      "source": [
        "trainX, valX, trainY, valY = train_test_split(trainX, trainY, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n5eGa1iehI5"
      },
      "source": [
        "Question3: Use one-hot encoding to convert target variable Y into categorical vectors. i.e., apply one-hot encoding to trainY and testY. Please refer to DNN Lab 2 jupyter notebook for similar task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "745ra_XtcTST"
      },
      "outputs": [],
      "source": [
        "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
        "valY = tf.keras.utils.to_categorical(valY, num_classes=10)\n",
        "testY = tf.keras.utils.to_categorical(testY, num_classes=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSGVJIWdelZt"
      },
      "source": [
        "Question4: Plot (using matplotlib) two data points from trainX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "EkZdPiATcX4V",
        "outputId": "eac7ce75-6e5e-4104-9570-659bc8514f9a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAEjCAYAAADOhyC+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHn0lEQVR4nO3deZScZZk+/qv2qt6ql/Sa7s4CIWFLgAAhw2KESIijwxIddRwNMx44YMgMoEfJDILiOAEZRcUYB0VQZzAz8DUqiDAYSPg5JpGEhC0LScjSSa/pTm/VXfvz+yOTlqbqekJ3eqm8uT7n1DlJ3VVPvfXW+971dFXdz+0yxhiIiIiIOIR7vDdAREREZCRpciMiIiKOosmNiIiIOIomNyIiIuIomtyIiIiIo2hyIyIiIo6iyY2IiIg4iiY3IiIi4iia3IiIiIij5MTkZt++fXC5XPi3f/u3ERtz7dq1cLlcWLt27bDuP3nyZLhcLrhcLtx2220jtl0ip5pf/epXA+eSy+XCpk2bRmxs5Q4R5zqR3DHsyc3jjz8+4okq11x++eX4+c9/jsWLF2fEHn30UZx55pkIBoOYNm0aHn744RN+PI2Z22OuXLkSH//4x1FfXw+Xy4Ubb7zxhLcRAH7zm9/gggsuQDAYRH19Pe69914kk0nHjHnhhRfi5z//OW6++WYAwNNPP63coWN93I9LjZn7Y743dwyJGabHHnvMADCvvPLKcIcYsHfvXgPAPPjggyc81jEvvfSSAWBeeumlYd1/0qRJZvHixVljP/zhDw0As2jRIvPII4+Yz3zmMwaAuf/++4e9vRoz98ecNGmSKS0tNddcc43xer30+BiKZ5991rhcLvPBD37QPPLII2bp0qXG7XabW265xXFjHssZ99xzj3KHjvWcOS41Zu6POZz5hiY3BEtQfX19pqyszPzlX/7loOs//elPm/z8fNPR0THkx9KYuT+mMcbs27fPpNNpY4wx+fn5I5LwzzrrLDNr1iyTSCQGrvvnf/5n43K5zPbt2x015qk+udGxnpvHpcbM/TGHM98Y1d/cxONx3HPPPZg9ezbC4TDy8/Nx+eWX46WXXqL3eeihhzBp0iSEQiF84AMfwJtvvplxmx07duBjH/sYSktLEQwGceGFF+I3v/nNcbenr68PO3bswOHDh4f9nF566SW0t7fj85///KDrlyxZgkgkgt/+9rca04FjAsCkSZPgcrmGdd9stm3bhm3btuHmm2+G1+sduP7zn/88jDF46qmnHDvm8Sh3jN+YgI51jZm7Y75fozq56e7uxo9//GPMmzcPDzzwAL761a+ira0NCxYswNatWzNu/7Of/Qzf+973sGTJEixbtgxvvvkmrrzySrS0tAzc5q233sIll1yC7du346677sK3vvUt5Ofn47rrrsPq1aut2/OnP/0JZ555Jr7//e8P+zlt2bIFwNHvAt9t9uzZcLvdA3GN6awxRwPbzpqaGtTW1o7oc8+1MY9HuWP8xhwNJ8txqTFzf8z3y3v8mwxfSUkJ9u3bB7/fP3DdTTfdhBkzZuDhhx/Go48+Ouj2u3fvxq5duzBx4kQAwDXXXIM5c+bggQcewLe//W0AwD/+4z+ivr4er7zyCgKBAICjs8DLLrsMX/7yl3H99deP5lNCU1MTPB4PKioqBl3v9/tRVlaGxsZGjenAMUdDU1MTAKC6ujojVl1dPeznfjKMeTzKHeM35mg4WY5LjZn7Y75fo/rJjcfjGUhO6XQaHR0dSCaTuPDCC/Hqq69m3P66664bSE4AcPHFF2POnDl49tlnAQAdHR148cUX8dd//dfo6enB4cOHcfjwYbS3t2PBggXYtWsXDh06RLdn3rx5MMbgq1/96rCfU39//6CE+27BYBD9/f0a04FjjoZj23HsjfbdTuS5nwxjHo9yx/iNORpOluNSY+b+mO/XqK9z89Of/hQzZ85EMBhEWVkZysvL8dvf/hZdXV0Zt502bVrGdWeccQb27dsH4OhfZ8YYfOUrX0F5efmgy7333gsAaG1tHdXnEwqFEI/Hs8ai0ShCoZDGdOCYo+HYdsRisYzYiTz3k2HM90O5Y3zGHA0ny3GpMXN/zPdrVCc3//Ef/4Ebb7wRp512Gh599FE899xzeOGFF3DllVcinU4Pebxj9/niF7+IF154Ievl9NNPH+mnMUh1dTVSqVRGIozH42hvb0dNTY3GdOCYo+HYR7XHPrp9t6ampmE/95NhzONR7hi/MUfDyXJcaszcH/P9GtXJzVNPPYWpU6fil7/8JT7zmc9gwYIFmD9/PqLRaNbb79q1K+O6t99+G5MnTwYATJ06FQDg8/kwf/78rJfCwsJRez4AcN555wFAxgJkmzZtQjqdHohrTGeNORrYdjY2NuLgwYMj+txzbczjUe4YvzFHw8lyXGrM3B/zfXvfRePDqDu/4YYbzNSpU00qlRq4bsOGDcblcplJkyYNXHdsrYpQKGQOHjw4cP3GjRsNAHP77bcPXDdv3jxTWlpqGhsbMx6vtbV14N/Z1qqIRCJm+/btpq2t7bjPz7ZWRWlpqfnIRz4y6Pq//du/NXl5eaa9vX3gura2NrN9+3YTiUSsj6Uxc3/M97Kt/dHZ2Wm2b99uOjs7jzvOjBkzzKxZs0wymRy47u677zYul8ts27bNUWMOZZ0b5Q4d6xpTYx4zLov43XrrrebrX/96xqW7u9v85Cc/MQDMX/3VX5l///d/N3fddZcpLi42Z599dtYEde6555rJkyebBx54wNx3332mtLTUlJWVDUpGb731likpKTFlZWXmrrvuMo888oj5+te/bj784Q+bmTNnDtwuW4I6dt2999573OdnW2V0xYoVBoD52Mc+Zn70ox+Zz372swaA+cY3vjHodvfee+/7XgxMY+b+mL/5zW8Gjm+/32/OP//8gf+/9tprA7c7dm489thjxx3z6aefNi6Xy1x55ZXmkUceMf/wD/9g3G63uemmmwbdzgljvndyo9yhYz0XjkuNmftjjsvkhl0aGhpMOp02//qv/2omTZpkAoGAOf/8880zzzxjFi9enDVBPfjgg+Zb3/qWqaurM4FAwFx++eWDTqRj9uzZYz772c+aqqoq4/P5zMSJE81HPvIR89RTTw3cZjQTlDHGPPLII2b69OnG7/eb0047zTz00EMDK3oeM5RkojFzf8zFixfT4/3dJ+RQTnxjjFm9erU577zzTCAQMLW1tebuu+828Xh80G2cMOZ7JzfKHTrWc+G41Ji5P+ZwJjcuY4zJ/LJKJk+ejLlz5+Lhhx9GKBRCfn7+eG+SyEkpHo+ju7sbq1atwtKlS/HKK69kLOrlJModIiPjRHLHqJeCn8xWrVqF8vJyfPnLXx7vTRE5aT377LMoLy/H0qVLx3tTxoxyh8iJO5HcoU9uiP/93/8dWGCorq4O06dPH+ctEjk5tbW14bXXXhv4/5w5c0a9Mmk8KXeIjIwTyR2a3IiIiIij6GspERERcRRNbkRERMRRNLkRERERR/GO1sArVqzAgw8+iObmZsyaNQsPP/wwLr744uPeL51Oo7GxEYWFhXC5XKO1eSJiYYxBT08Pampq4HaP3d9Aw80bgHKHyHgbr7zBNmbErVq1yvj9fvOTn/zEvPXWW+amm24yxcXFpqWl5bj3bWhosC7wpYsuuozdpaGhYTRSRFYnkjeMUe7QRZdcuYxl3mBGpVpqzpw5uOiii/D9738fwNG/qOrq6rB06VLcdddd1vt2dXWhuLgY9ZOnwe32ZMTdCNL7BgIFNFZcWU1jafAuwy0H3qExj4nTmMtYOhcf569K4+IfqLk8PhqbUDWRxrwBvpBYX6SPxvx+/nj2kjz+HNOpFI15ffy5x+MJGuuL8dciPz9EY/4Af35pk6Qxr8k8Nt/NY/mrJWbZVttfO2nLYdMb6aWxY2XJWbclnn1bUqkkdr76e3R2diIcDvMHHkEnkjeAP+eO6xddD58v83X1lPLjLhXkr+fOnW/T2MQ6vj0efvigfZ/l+Ojidywvr+CDAgj6eH6M9vFjJBrrobG+GH+80hLe1XnmuefTWG2tJVf5eO7s7eW5asurr9LYwUaex3u6u2mssKjccr9OGjtzMn+/+exnb6QxAPjjG2/QWENTM43NOpt/wtnWcoDGyiaU0FhHbDuN7Wx8KeO6RCyNX/9w75jmDWbEv5aKx+PYvHkzli1bNnCd2+3G/PnzsX79+ozbx2IxxGJ/Pnt6enr+7z6erJMbj4snIY+HPx2v1/ImZpncuD2Wx0vzmMtY3omON7nJ8rwH7jrM5+j1+mnM4+WTBtuYPh8f0za5Sbn5m4zPMrlJW/aplw8Jr2U7s70J/vnx+BvQ8Sc3PJ62zHuHO7mxPUdPgr9ZetL2v23G6uudoeYNgOcOn88HX5ZJuTfA920qYDnPfTzmC9AQPJZP5b1eHkx6+WtiOz+OxvnxnLLcN5niz9F2btkeLxDgE61QiP/BYZvcpFJ83/j9/Bzwevlz91hy/HDv57fsl/z8PBoDgGCQ7zd/gD9H2z61jWm9n8uSOy3nTC58LTziX4odPnwYqVQKlZWVg66vrKxEc3PmrHP58uUIh8MDl7o6y59CIuJIQ80bgHKHiHDjXi21bNkydHV1DVwaGhrGe5NE5CSg3CEizIh/LTVhwgR4PB60tLQMur6lpQVVVVUZtw8EAggELJ/tiojjDTVvAModIsKN+OTG7/dj9uzZWLNmDa677joAR38YuGbNGtx2223vexyXicOV5XcNqTT/ArgvEqWx6EH+o8qA5TtH2++tk27+vaonZfkVXoJvCwAY249xLdvTc5h/B1o8gX9kn4zy7fFYtqW3h/9AMRiy/R6Hs32nbtL8tyO2H836LN9T51l+bJyM8d8iwW3/TjlBfqgLAIkEHzeZ5M8xEOLfm9vuZ/sBt5t8N27G+DvzkcobABCcEYI/mPmax6P82Gpt4p/6lBRnn1wBQJ63lMZi/fzHn/lFPFeVFRbz+/ntv9fgGQmoyJ9AY/EkP0caOztprLyUj/mhK/+KxsrK+X57dcsfaKyokE9mi4vLaOxwO38t3C7+BUZhES+a6I/wHyK7bD+4cll+dAegN91EYwUT+Vt21PJ+9OKatTRWWMSPqYrTeJFOKpm5v1OxJIA99D5jaVTWubnzzjuxePFiXHjhhbj44ovxne98B5FIBH/3d383Gg8nIg6gvCEiI2VUJjef+MQn0NbWhnvuuQfNzc0477zz8Nxzz2X8WFBE5BjlDREZKaO2QvFtt9025I+TReTUprwhIiNh3KulREREREaSJjciIiLiKJrciIiIiKOM2m9uTpRJG5gsbRHsrbB4iV06EeF3s+wFDyzlwJZtCVtKFouCvLwOANyWMuM8SzlwcSkvWd21v43G4n28LLU4zEshfZa+TPEoH9NWZJy0PHeXpTVByM/L4ON9vG9OIsgf76zpZ9BYa8thGgOApsZWGvNYykS9lvYaPsvy8rbl1d/douC9/GR5+dRxSt1zmTeYhjeYmQu6LD2Eetv561mQx8/XRB8/7soKeZm0KbCU56csa/f029t+hAJ8aYPuLn4eeHy8NLuyiB9bnhRfgqD7SCONeb08P3R189ci0stfw2iML03hs/TJMJa84vXw/J9fxPv1FVpK5GHrOwggEeWv074jvNfTxIp6y/bwMvmu/g4aa3uT57H8cGaOSFreLseaPrkRERERR9HkRkRERBxFkxsRERFxFE1uRERExFE0uRERERFH0eRGREREHCVnS8FdaQ9cyCx7dMFWCm4Zz8Xvl0r20ZilChLTJk+ksQ9cfgWNVR2nV87hVt7BtrjQ0sG1upbGnnz6BRo70MTLxKvq+HPstnRh7+zgJaKpJC+DjVq6e3tJ2TIAFPp5Wbrfz+83d/ZMGpswgZfHvvbqVhoDgCNdfOmBwnxeQur2WEraLSXdKUvnb49lTJ8v+36zleTnOn+XG4FY5t9trm6+/4JBfl75fDx3HGk5QGNlE8+isbxQDY25Lccr/LzbPADk5fGlGw538DLqovwiGkv7Ld3o+/m+2bSed/eeMf00GvNZjr20Jf8nLXXIoZClm7ol/yfifJ/VTOS58bzzL6axgNfe2d0d5fs71cn3zdZX/0Rjf/XXvEN7Ism353fPPEljHZ37M65LJnInb+iTGxEREXEUTW5ERETEUTS5EREREUfR5EZEREQcRZMbERERcRRNbkRERMRRcrcU3LjhMlnmXi7eUTVbF/FjElFemltexTu4Lph3KY3NmsHLGc89/wIaK63g3bsB4O23Xqexvs52Pq6lE/k1H7qcxhJufr9gmO+bbTvfobEX/+dlGovG+GsRCvCy5Vnn8tLa2efxku7qqgoaKyjiZZDPPP0MjVWWl9AYAPgs3Zn7Irzc3aa3l++3hKUU3O2ydD1m5fXH6Vycy1KJFJLuzP1RlseXYCgK83OyrW03jXksK1McbuJLOuSH+Ovl8/OlAory+XEFACnw5RnSab48g9fNz7tEPy+xLrKUnvuCPK90x/h29kT4dvYf4eX8PksVciifv1B5Hr6MRF8PP3fSaX4+mhQ/x41laQEA8OTxUvAiP1/uI8qbe6Orky/3UTd9Fo2dcfaZNNawN3OHJ+IJALwkfSzpkxsRERFxFE1uRERExFE0uRERERFH0eRGREREHEWTGxEREXEUTW5ERETEUXK2FDztSmYt+zbgJZRFYV5Cef6Ms2ls1tm8xPiyKz5AY6E8/ngFFbzstC9t7+zb3NZCY52Nh2isv4+XH7b18NLLN3Zldnc9pivO6yvdPl5GnbB09z73TF5C/4HLLqSxiy7i5d6l5eU0tnH9Rhp7fes2Gjv99Mk0dto5M2gMAPbs56/h+vVv0FjSUtKdjPGSXKT43ynxpKWbeCL7mClLh+Vc19ixG74snbULXPyc7Df8/OiO9NBYuIgfd+kIP3fiMZ4D+iJ83wei/PgAgGSK1wNH+3pprNvrpzF3L++aXVDC30ICbn5MuizLT7hdvFQ6YDksvSleQt6T5q9h0FJC7vJYlkSwlIIn+vmSHT6P/TOFkD9MY9NnVNNYX4I//zd3b6axA50NNFZTxzuf+0JTMq6LRXmuGWsj/snNV7/6VbhcrkGXGTPsbwQicmpT3hCRkTQqn9ycffbZ+P3vf//nB2ELhYmI/B/lDREZKaOSPbxeL6qq7Kvwioi8m/KGiIyUUflB8a5du1BTU4OpU6fi05/+NA4cOEBvG4vF0N3dPegiIqeeoeQNQLlDRLgRn9zMmTMHjz/+OJ577jmsXLkSe/fuxeWXX46enuw/6Fq+fDnC4fDApa6ubqQ3SURy3FDzBqDcISLciE9uFi5ciI9//OOYOXMmFixYgGeffRadnZ347//+76y3X7ZsGbq6ugYuDQ38l9si4kxDzRuAcoeIcKP+i73i4mKcccYZ2L07e2fdQCCAQCBbWWD2ErzSggL6WB+9ZiGNXX/tNTRWVcXLOcNlvKN0wlIl+MYbr9HY/778Ir8jgIPv7KGx4jzeFbi9s5PGopZGtI37+eP1xnidZDLN58aVJcU0dtXlvNx7ymReerhv1w4aW/viczTW1Mi7M5dP4L/xePn/W0tjrd38EwUAiKZ4p+Gefr7fQkVFfFBLiWwizkuL+6O8ZNXrzf76pixltWPheHkD4Lmjp+8IvMnMLtdtXZZOzYZ3xU75eP1xfpifH6EgL6/2uHjMZOloPhBL87Lso4/JS6xNhCes9sO8dNnfx4+fCQW8bDloyTkhw88BE+JLTHRZutVH0vx1SiT58Rzt419nJsDvVxTkHdFLC/kyId6kvSt42rJMgKuA5//isjIa23uQP4/df+LLYcRPP0JjaXfmmLYlDsbaqC/i19vbiz179qC6mtfni4i8m/KGiJyIEZ/cfPGLX8S6deuwb98+/PGPf8T1118Pj8eDT33qUyP9UCLiEMobIjKSRvxrqYMHD+JTn/oU2tvbUV5ejssuuwwbNmxAuWUFWRE5tSlviMhIGvHJzapVq0Z6SBFxOOUNERlJapwpIiIijqLJjYiIiDhKzjZv8bjd8LgzyzNPn5TZifQYW+fvigpe8uvNC9LY/gbeMbupmXd+fmPzJhrrtJQmA0BNJd9Wf4CXkO7d/w6NFYV52eKUWl7u3nGYdxIuKealh0XFvJxz0x/X0Nibm/lrEenl2+LjFbAomzCBxlwJXh5cX81/71FkWZIAAA61ddFYe3sbjUVTvDu138v3aSrFu/F6Pbz0NEk6ho93KfiJKEIFfFlSW7KYp7uOHl4O7Afff8ZSJt1lWS6guoIf52XFvLza1cuPDwBwW7p7hy1l263t/HiNxCzHQoA/j6nn8nw8oYYv+XDkcCeNRXt5afLbLXypiP4ofw6JOI/FLWXbngQv2fdaup4nkvbO7s3tB2ks0s6XRqgsO50/Zjsvky9w81x2ZD9/r0pnKZNPWDqTjzV9ciMiIiKOosmNiIiIOIomNyIiIuIomtyIiIiIo2hyIyIiIo6iyY2IiIg4Ss6Wgpt0Omtf8J4eXl7ZZSnn/N3vnqex1o5WGuO9goFIhG9LaQHvClsQ4uWaAOBxWbpGB3g58KT6yTTW29tJY9U1vBT87GnFNFaQz0sIXV7evbe1jXcgjkZ5yWKlpXt7MsG7JUd6ebluW4SXOlqacGNSbQ0PAii1dOiNJnnn3F0NvEzcbWmznCYl3QAAl6V9vSH72+ROSedQVRRWw+/PPMeSCb7fJxXycyBs6bSd5+Ndmru7LGXblu7WPjc//6M+e8qOWLoy51u6bbd37bOMyo+7iTOn09glH7qcxrIt83FMxyGej10ufpzvObSLxjrf6aSxRMKyREAbzx2miOdxr+W46LecqgDQ3cFzWWd3E431HOT3SyZ49/pU3BIznTTmzs88LpIqBRcREREZHZrciIiIiKNociMiIiKOosmNiIiIOIomNyIiIuIomtyIiIiIo2hyIyIiIo6Ss+vcpNIGJsv6Cm8f2Evv8/3HfkRjxQV8TZZLLpxNY4koX+cgFePrWEzID9LYgYb9NAYApSV8PZfaqjoaS0T5GheNDXw9l0SUr7lhqvl6FNEEX5Omv4+vuWBcfF2FuGV9lcOtfI2HzvbDNFaQx1/7gvwiGntn3z4aKynhayoBQE8fXwMp4LasRZJ1daej+rq7aCxpWYskneb7NJXO/hqmUyl6n1xXlleEQCBzDRJPiu+jsGUNGFea/w2Yl8fXMyny8XMgZlmPJtrP7xfKt6+RdcTLt/VAK89lPk8JjRkXP883rH+Vxi644EIau/Qv5tBY3ukTaay8lufGrhh/fq3tR2gsEuHrGPX4+TETCPp4zM+Pp/4++7lli3tcYRo70s4X0PEHeM41ls3psyzK48qSq5PJ3Mkb+uRGREREHEWTGxEREXEUTW5ERETEUTS5EREREUfR5EZEREQcRZMbERERcZQhl4K//PLLePDBB7F582Y0NTVh9erVuO666wbixhjce++9+NGPfoTOzk5ceumlWLlyJaZNmzakxzEeF4w7s3wtluSlsgnDy5Yvv+wKGivN5+WcR9p5KaArwEsI29p4aXJ/nJeBAsCBhgYa83t5iTnfM0BvLy+T7I8d5Hf08nLH7m5e7pxO8K2pqqmmsZSblxJ2dHbQWEF+IY0FLbG9BxtpbMfefTR2XuE5NAYA5VVVNBZvbOGxPv5apMDLgBNpvt+MpbyeHTXGMt5wjFXeAICSwgkIBjPPzUQvLwdOpXj5dX6Il992HOHneX4Bf738QUvqTfNz3O3i5yMAvNPIj+fGg638ji6eA/MCfLmEN97YRmNP/+Z5Gjtrxhk0lkrx/FhSWkpjcy65mMbe2fkOjXW08X121qQpNOb1WJa0sJRzd/XzZTkAoLComD+mLR93HeCDuvnnGH4/j8Xi/LhwxTJzh0nacs3YGvInN5FIBLNmzcKKFSuyxr/5zW/ie9/7Hn74wx9i48aNyM/Px4IFCxCN8jVhRMTZlDdEZCwN+ZObhQsXYuHChVljxhh85zvfwd13341rr70WAPCzn/0MlZWV+NWvfoVPfvKTJ7a1InJSUt4QkbE0or+52bt3L5qbmzF//vyB68LhMObMmYP169dnvU8sFkN3d/egi4icOoaTNwDlDhHhRnRy09x89LvEysrKQddXVlYOxN5r+fLlCIfDA5e6Ot5eQEScZzh5A1DuEBFu3Kulli1bhq6uroFLg+XHtCIixyh3iAgzopObqv+rEGlpGVwN0tLSMhB7r0AggKKiokEXETl1DCdvAModIsKNaFfwKVOmoKqqCmvWrMF5550HAOju7sbGjRtx6623DmmslAFMlirsdNLS2TfISzanTp5MYy1NvEt3xNL52+fjZXnGzWMFhbwDLwBELGXbrZ3tNOb18pczlM+71Ho8vIQ+HuUlshNrKvj9LB3DS8v4m1BJKd831RW8I3AiyksvDzbyrzZaDvNS3rww387TzphBYwDQ0sTLvd/ezUs2e2J8f3t8/Ni3rQPgwtBLwV22VsEjbCTzBgDEEgm4spS+umxrJVjKel0efsdQHj/P02lLR+kAP1cLy3kX+0Tc9iSAaXX8nJxax8+ftna+rENTB+8M3dXH80pbRz+N7dzDlzzY8fZeGrtq/jwaKyuZQGN1ZZU05unlz72khJeeJ+P8mNn/Ds85vfFeGgOAsyfz5Q/iCf5alAZ52bYtH/dY3uNKwjwfe7O8/8Xjcfxx/Sv0PmNpyJOb3t5e7N69e+D/e/fuxdatW1FaWor6+nrcfvvt+Jd/+RdMmzYNU6ZMwVe+8hXU1NQMWtNCRE4tyhsiMpaGPLnZtGkTPvjBDw78/8477wQALF68GI8//ji+9KUvIRKJ4Oabb0ZnZycuu+wyPPfccwgG+cJUIuJsyhsiMpaGPLmZN28eTLbvi/6Py+XCfffdh/vuu++ENkxEnEN5Q0TG0rhXS4mIiIiMJE1uRERExFE0uRERERFHGdFS8JHkSaezzrxKCnkn7tIiPlfzuHg5bFER7xp98CAvWUykeHldfT1fLTVcXExjAODx8OeRl59PY7F+XnrpMryE1OPmpeABS+fz/AK+LT39vKTZpqebl0km4vw1PNLKO4bn+3mJ5NS6yTRWVFpGY02W8nIA2LL1dRprbuXl524f7ySdTvPX0AVelmoL0V/BWO6T60y0DyZLKbtJ8PL2hKWLvdfLz/NILz9ebevu2F7LaIyX+/b32xuJBvz8hfN6eV6pnlBLY/U9vEu3sfx9nEry3PHa9n00Fknw32a19/PXoqSY5/FQIY/l5fHS+3xLvo0Ynm+jcZ7/wvn2H8nH+csPn2V/V0yspjGPpSt4MsXzv89SXp7IsrZCfzSKX/ziF/Q+Y0mf3IiIiIijaHIjIiIijqLJjYiIiDiKJjciIiLiKJrciIiIiKNociMiIiKOkrOl4Pl+f9YS5YsvOIve59wzp9LYwYY9NBbp56WOlVW8y67f0hXcVkLd1c270ALZu60OxJK8hNTt4fdDkpdRe728/DhuKb/uPNREY/1xvk9tXchjljrI7s4uGqspraIx4+KPV13OSz07LGXp23e+TWMA0NTSRmNpS52127Ktbjc/XdMpXuZsKztmxeDG0tE61yWiXfCYzGM6neZ/y0V5hTESKUsptOW8ivbzfRiLR2gsHObHpC2vAIDLbXlMS0fpaIKXLhfn88e89PzzaOwPW/bT2O9ffpPGTj97Mo0d6OTLKORbypa7u/hz9/r4eRUM8Nzos5TWx2PdNOZx2d923QGeHzxeft+iIl7S3tbK81GeZb8V5/HXvrW9JfPKqH2pgrGkT25ERETEUTS5EREREUfR5EZEREQcRZMbERERcRRNbkRERMRRNLkRERERR8nZUvCKCRXwZil7q504kd6n8wjvDH2ky1Ka5+NdWtvaeAlheXk5jfX28Y6xJWX8fgBQUMBL+got3W0bD/EO5v4gf6m7e3hp+oSyCTSWtnSabWrdS2PV1TU0lkzykmafpWQ9mMfLZ+OWbtDdEV4Cu+U13tm7sSVLGeS79Fo6tLs9/HnYuizbWnUbS+W2LQYXKQXn/cJzXkV1NULBzBLWnq5Oep/8JN/vofw8GuuP8uMnHuNlsf39/H5pw0vPiyznPwC4Xfx52EqQLVXicPn48gSFIf48ygr583i7l+9TU3ImjXX5wjS2eVsDjW3ffYjG0rFO/niWPF5fz/N0XgF/T+np4mMCQDCPL+mRsuTHvr5OGisI89fe4+aPl7AsI5GIZ25LwpJrx5o+uRERERFH0eRGREREHEWTGxEREXEUTW5ERETEUTS5EREREUfR5EZEREQcZcil4C+//DIefPBBbN68GU1NTVi9ejWuu+66gfiNN96In/70p4Pus2DBAjz33HNDepxoKg4vMsvQ+mK8C2/IxzuYJlO8tLW4lJcRG8NL2yzNrVFcWkJjsbilBTGA1r37aOyM6dNpLJhv6XDdzrvp2jp4m27eidtjKQXvj/La0njM8niGlzufefY5NOb38NLLhkONNLbznXdo7FBLK431W54DALg9llMrS7f7Y9Iu/vxhKcs0xhYbep24ZbhhGau8AQDpVBLpVOY+jlqOSa+Hd0aOxfj+y8/npdllZfy17Ozkx0BPNy8V7osc57hz88cMh4torKCAP49+S6fnWB9fYiPk5yXGbhTTWCrEl/voS/Ec33lgO43t2seXpkgkeYf2fS38PG5o4tsyqZqXrBcX2ju7+y2dv/PC1TQWifDnkZfHc3XKcq7HLcd+YWFlxnVen73MfSwN+ZObSCSCWbNmYcWKFfQ211xzDZqamgYuv/jFL05oI0Xk5Ka8ISJjacif3CxcuBALFy603iYQCKCqqmrYGyUizqK8ISJjaVR+c7N27VpUVFRg+vTpuPXWW9He3k5vG4vF0N3dPegiIqeeoeQNQLlDRLgRn9xcc801+NnPfoY1a9bggQcewLp167Bw4UKkUtl/u7J8+XKEw+GBS11d3UhvkojkuKHmDUC5Q0S4Ee8t9clPfnLg3+eeey5mzpyJ0047DWvXrsVVV12Vcftly5bhzjvvHPh/d3e3kpTIKWaoeQNQ7hARbtRLwadOnYoJEyZg9+7dWeOBQABFRUWDLiJyajte3gCUO0SEG/Wu4AcPHkR7ezuqq3kJWzaRSC88WWqtOzr59+qTJvLHSBk+j2s/wsudfT5ezlhQxMu9vZYO1k1NTTQGAD4/f1k62tpobNoMXiZeWpFZtndMXoCXUdvKj12WztHltm7i4GWwUUs3ba+lm7bL0tm9z1Je/vb+/TQWiVk6e7vtp47L0p3Z0twbxvI1TNp2x2F28WZV4tZO4mNguHkDANLJNNLJzOPW6+OvSWlZMY31dfPXpDCPH+eFRfyYTCV4XvG6ecm6y3oMAOFivhwEXPx5eP2W7s89/DwI+flzLKvlPw4PtdbQWE8nH7PjCM8d8Z5OGksm+HPw+PkyAHzhEeBAM++I3nKYb8sFZ59mGRWYaFlCIBbj73+WVI1Uij8Tl4cfi7sP8qUyAv7Mzu7RmKW9/Bgb8uSmt7d30F9Te/fuxdatW1FaWorS0lJ87Wtfw6JFi1BVVYU9e/bgS1/6Ek4//XQsWLBgRDdcRE4eyhsiMpaGPLnZtGkTPvjBDw78/9h33osXL8bKlSvx+uuv46c//Sk6OztRU1ODq6++Gl//+tcRCNgXLhIR51LeEJGxNOTJzbx586wrnj7//PMntEEi4jzKGyIyltRbSkRERBxFkxsRERFxFE1uRERExFFGvRR8uPr7+rJ2nbZ1tz5r+jQaC4Z419vDljEnTuQdamNx/hsCW+lhXpCXHgJAMMRLnvMsscOWMvFzL7iYxqKWbrIxS8zn4SWLkcJeGoun+GHXH+Ud072W8utEmm/La9t20NjhLr4MQMDW2fs4fxekbaXUaV6SC5elntPWMXzYRmPM8RUI+hEIZp4n8SQ/d+Ix3vnatjRDMsXPj44O2xITNIT+ft752+2x/8A6meQlv909HTTmt/xwOxDg+y2V4KW/MUu5e1FhGY0Zy7lskjzmTfDcEQrxbfGHCmjMluPicb5f2tv5vn59eyONAUDoPF7uXlLMc0d3Dy9N93r5c+zs4m1OfCl+LBZlKQX3jfMSEu+mT25ERETEUTS5EREREUfR5EZEREQcRZMbERERcRRNbkRERMRRNLkRERERR8nZUvBUKp21M3FvhJdYH+44QmM+Hy91LCoqpjG/5X4dHZ00VhzmY5ZPKKcxAOjq5mWEcUvX1QOHeIlhsJB3MDcpXn68w1JGPbGad/0tDPPuxJF+XnZbUcnHLLB0dV7z8noa2/PObhrz+Xg5p9sy909ba70Ba5fuYZZ029oX2GKnmn379iPgzyz99Vs6WOeHeKyqspTGDh7axzfEUtZfVMTPjyOdvDQ3EbcsFQCgpoYvXREM8Mfs7+clxskYLy9PWcqv+yLFNOYq5MthhPIt512UlzubHr78REFeZtnyMV4/z/GpOM+3iQR/LVxufjw1NPP3KQBIbuJLCHz6Ex+msTw/zwGRbr5v+vp5p/ECf5jGigsy31P8Xp7bx5o+uRERERFH0eRGREREHEWTGxEREXEUTW5ERETEUTS5EREREUfR5EZEREQcJWdLwdNwI9vcq+FQE71PQQHvfHruOWfTWLiYl0mnU7xEsr2dl/QF/bzUsTXRSmMAEArx0kRb995QkJcfvrp5E43V1k6isbSlE3ckxveN1xILWLrw9vbxUv+ki5ekptM8lkzwzrYeD+/A607zmHFZOnsf3SIacdmqti1V4sMt93ZZSs+dWELudfngdWWW+KcS/G+5KHiJcb+t/Njw88O2bIO/nJ+r4eIiGisvr6ExAKitraexmKXbeOvhNh47dIDGkuB5zlMxg8bCZXzJh6p6/joFErzUuOkQX0LjSFcPjQV9vJzdb8mpiTi/XyrJX3uPZUkLAGjt4Pd9+rcbaezCmdNpLN7P36vKyy3l3kV8GYR9+zOPi6jlmB9r+uRGREREHEWTGxEREXEUTW5ERETEUTS5EREREUfR5EZEREQcRZMbERERcZQhlYIvX74cv/zlL7Fjxw6EQiH8xV/8BR544AFMn/7nErRoNIovfOELWLVqFWKxGBYsWIAf/OAHqKysHNKGGZcHxpU594pbOlh3WTqfhkK8K2xZCS8FP2TptF1QUEhjLS0tNGbS9jLi+nre2dfVzZ//kc5OGtv5zn4a27VnH43VTZpGY/EkLzFev5GXLBZYOqZPKOH7dMaUahrLy+cl8m4P3860rctyavhl0ra+38bSMdxluefJXLY9lrnD7ytBIEun51TS1lWdlxj3WLpN9/bw8mpbCb6l2TQ8Xp6Wi0v5+QEAJaW8jLy7kz+P4iQfN+Dm5eW7mixl8vl8zLJqHssv4zvHu5d3zD6wj+e4ht5DNFZnKa/3+DOXFDjG7eavryVkjQFA2sMfc28T7xhfVMiXSTlzUoXlEfn+7k/w97FgXuaxb9z8fBhrQ/rkZt26dViyZAk2bNiAF154AYlEAldffTUikcjAbe644w48/fTTePLJJ7Fu3To0NjbihhtuGPENF5GTh3KHiIylIX1y89xzzw36/+OPP46Kigps3rwZV1xxBbq6uvDoo4/iiSeewJVXXgkAeOyxx3DmmWdiw4YNuOSSS0Zuy0XkpKHcISJj6YR+c9PVdfQjwtLSo6sYbt68GYlEAvPnzx+4zYwZM1BfX4/169dnHSMWi6G7u3vQRUScTblDREbTsCc36XQat99+Oy699FKcc845AIDm5mb4/X4UFxcPum1lZSWam5uzjrN8+XKEw+GBS11d3XA3SUROAsodIjLahj25WbJkCd58802sWrXqhDZg2bJl6OrqGrg0NDSc0HgiktuUO0RktA2rceZtt92GZ555Bi+//DJqa2sHrq+qqkI8HkdnZ+egv8BaWlpQVZW9UVogEEDA0gxSRJxDuUNExsKQJjfGGCxduhSrV6/G2rVrMWXKlEHx2bNnw+fzYc2aNVi0aBEAYOfOnThw4ADmzp07tC1zuY5e3iNtKYftflflxXs1NfOStkgPv5+t/DYQ4B1jy8t56V1vr/23Ab2W59Hewbv3ur28hNBWYrxly2s09vY7vIQyleJjxnp5yWbK8nlhfS3fbxMrr6ax2jpePl9by0s9395j+2vfUrNpKfM9es/hlXSn05Zu4m6+46yl5zlQQj6WucMfTMEfyOwS7/Xx+0T7+B7s6+PlrXn5vMO92833e2trK40FAjwt7911kMYAIBnjz6OtjeeOcBFfDiPe76Gxdw7yTtyhMO+aXWZ55/G28xfKtY/vt+62nfx+ebx7udvDHy9iycVuy/no8/Ex08dZCiSZtixZ4OavxY53ePf28nA+jU2ZVEZj/VGex12uzD8sXK7xzzXHDGlys2TJEjzxxBP49a9/jcLCwoHvwsPhMEKhEMLhMD73uc/hzjvvRGlpKYqKirB06VLMnTtX1Q4ipzDlDhEZS0Oa3KxcuRIAMG/evEHXP/bYY7jxxhsBAA899BDcbjcWLVo0aCEuETl1KXeIyFga8tdSxxMMBrFixQqsWLFi2BslIs6i3CEiY0m9pURERMRRNLkRERERR9HkRkRERBxlWOvcjAmTRrbmySnDS2VbD/OOqes3b6KxyZaVTafWTaKx2gnZ198AgMPtfFsmTZlKYwAQCvESc1uJYU9fP429tpN3zI0n+T5NdfFSQFsBstfD581eS5fuTkvn4l7euBkTJhTT2LlnzuBj9vLHa2riZaduNy+7B4C0paO4rSu49ZcpljJxWyfpVIqXnrLfwuRA9fiwud1HL+9l0vyYLC3jXaq7IvzAy8vj56rHUhabivNzwNa9vKiwmMYAIBLhy0y0tvKu0fEoL3ePWlqYN7fzxzvTx8vkTRcvE+/u4GPW+HhJd8jP92lHwrJsRYI/P5fl73+v5Zzz2tYdOF65tOW18Hr58WbLKzsO7aaxklJ+v8L8Uhrz+TKfv8fH34PGmj65EREREUfR5EZEREQcRZMbERERcRRNbkRERMRRNLkRERERR9HkRkRERBwld0vBkb3s1d6MmQdb2g7TmMfDd0NtFe82HQjwssSKSl4mfqTH3hU80sdLE8tKeQfXLVvforH9DY005vNndnc9JhDgMVuJcTKZ2ZX5GJelm3hfPy+7fWPbLhorLSqmsSn1vPS+31J22de3kca6eyx16QDclgM1xSu64TpOt3E6puW1sHUvZo83zM3ICfG+INypzOM2HuMdnvMKK2msMGwp6U7w46C/v4/GkOLHXUU535ayijAfE0BDw17L9vBlD8LFvCt40m0pE+/n+8ab4Mfdto2/52N28fN82qzZNFZfmkdjext4R/TeXl5e7ffx/Je2LM1gW7LD7eKdvQEgHuf7O2lZtiNkWZagt9dSet/F3298bp5XYrHMY78/as+LY0mf3IiIiIijaHIjIiIijqLJjYiIiDiKJjciIiLiKJrciIiIiKNociMiIiKOksOl4CPL1uW4ubmFxja9uoXG3Ja54Xnnn09jZTU1fGMA7N7NSyHf3LGdxvqivCPrBRdcQGPbt/MxbWWJtlJIG1u5s23M7dt30Nikal6yf8YZZ9DYmdNn0ZgxvPP3+g0baAwAeizdxn3WDt62OnEesu03W8zjYWWpJ29bcF+eC75A5s6yLbHQ1NRBY8UlvEy6trqWxhoP8bLsji5emhyN8XMuFre/Lj09PAeEQrxUuKamnMY2bm2mMZOlHPiY3kM7aaxhBy8F7+/YT2M7/ZYO1kX8dXKlW2ms17LPvF5+zPj9PD/YOobzc+4oW851uXhJdzDIy9b9lg7tXj8voU9YOqabdOZyHybNt32s6ZMbERERcRRNbkRERMRRNLkRERERR9HkRkRERBxFkxsRERFxFE1uRERExFGGNLlZvnw5LrroIhQWFqKiogLXXXcddu4cXO43b948uFyuQZdbbrllRDdaRE4uyh0iMpaGtM7NunXrsGTJElx00UVIJpP4p3/6J1x99dXYtm0b8vPzB25300034b777hv4f14er6NnjiW3oTCWxWxc1jbz/HEaDjXRWFfnWhrbsecdGvvAB+dZtgWotKzZ0trG1+OostzPG+BrIAQssVdffZXGEgm+5oLbzefNtphNd083jb21420aK5tQSWNnTJtGY1WVfD2idNK+3sifXvkTjfX09NCYz7JvEukUjdnOFdt5wdbAGe4aRsxY5o7yCYUIBTPXdOmNdtH79PR10pirk6/dEfRY1vUwfB8Wl1TQWDLJX+dEgscAoLMjQmOBoI/Gpk46ncaeeIavSRPv5zkgfvgAjZkUXwfKBb7fXtnFz6vycCEf0/A1fuKWPJZI8G2JRvkaPz4f39fHY8uPtrV1kkn+PPr5cjXYvmcPjU2cwPdpVfmEjOs8XvvxOZaGNLl57rnnBv3/8ccfR0VFBTZv3owrrrhi4Pq8vDxUVVWNzBaKyElPuUNExtIJ/eamq+voX0KlpaWDrv/P//xPTJgwAeeccw6WLVuGvr4+OkYsFkN3d/egi4g4m3KHiIymYbdfSKfTuP3223HppZfinHPOGbj+b/7mbzBp0iTU1NTg9ddfx5e//GXs3LkTv/zlL7OOs3z5cnzta18b7maIyElGuUNERtuwJzdLlizBm2++iT/84Q+Drr/55psH/n3uueeiuroaV111Ffbs2YPTTjstY5xly5bhzjvvHPh/d3c36urqhrtZIpLjlDtEZLQNa3Jz22234ZlnnsHLL7+M2lreOA4A5syZAwDYvXt31gQVCASsP2gVEedQ7hCRsTCkyY0xBkuXLsXq1auxdu1aTJky5bj32bp1KwCgurp6WBsoIic/5Q4RGUtDmtwsWbIETzzxBH7961+jsLAQzc3NAIBwOIxQKIQ9e/bgiSeewIc//GGUlZXh9ddfxx133IErrrgCM2fOHNKGDacU3Dqepdzb9rtqt4fHeiylgG/t2Eljh5pbLNsCnHfeeTSWrcT1mC2vvUZj0TivBcz2V/ExkydPprG33nqLxmzljLbSZFsMltCOXTt40FJa2t/HS1JLi0tobNa559AYAFRV8lLfLVu20Nj27dtpzHYEG0twJM+j4RrL3OHPy0MglHmeVFuqsGJ7+ZIPhXlhGkulkjRWWcWPH5eLlwqHgrz8tr2jlcYAYGItf46pFC9b37GL56sDjc00Vo5SGgtEeOl9KmopWQ/xcueOfv4cIolOGkt7eT6Kx/tpzOMa3pIWqdTwS6KHu1SGPa/y942+ggIaO9jMX0OTyswr0bhlaYQxNqTJzcqVKwEcXWzr3R577DHceOON8Pv9+P3vf4/vfOc7iEQiqKurw6JFi3D33XeP2AaLyMlHuUNExtKQv5ayqaurw7p1605og0TEeZQ7RGQsqbeUiIiIOIomNyIiIuIomtyIiIiIo2hyIyIiIo4y7BWKR5vL5YbLUoaX/U6WHy2mh1cOm7LUH7s9vNO421J+29nFy+sAYK3lh5VTp06lMX+Al1A2HDpIY/39vBTy3HPPpbHhl3vbOk7bapp5KJbgZfmvvbmVxg4d3E9jM07jHcPzCnm5LgAE8/Jp7NLLLuP3s5T6b9rCO7TLn7V1HEEwmLm438RqXp4/obiYxkrCvKv8vv3v0FhLSzuNBQJFNOYpDdFY2lK2DADhEF/UsLRsIo0d7uU9vGwdpW1vIHmJDhpLR3gpuKuInwNuS47rt3T39lnuV2A5l5MJXupv6woei/GdZuvsDdiXbrCNa41ZSrTr62torLaELy3gS2Yei8N8mx0V+uRGREREHEWTGxEREXEUTW5ERETEUTS5EREREUfR5EZEREQcRZMbERERcZScLQU/Wiw8tLoya+m4JWTvesOlrf1yeLmzy2N/RNuw7+zfQ2O2MmKfn5etpwwvd2xuaeT3S/P72VtYW56gpQzSbS0Tt4xpee07ejpprLmLl/JW+OynzpY33qCxst1lNGYrvW9pP0xj+/fzknaX27Lf2GtxnF5Quayzqx3BaGa5rcfP90NRkJdfp9oP0JgbvPy4t4uXO3fEjtBYQZjv+6ppvNM4AHQ38sf0gJcguy1ZMJnkZcRN0TYaK+15m8a6unkXdleKd2HPD/IO1l4v77TudfMS+VAwj8ZMgOdxn48/nq0reDptWwrDvsTGcDuRG0usp43nlYrJM2msrzMz/xuP/bmNJX1yIyIiIo6iyY2IiIg4iiY3IiIi4iia3IiIiIijaHIjIiIijqLJjYiIiDhKzpaCH60lzlK6aS0jPs5wLGSteh1mm1PbmPYHtFVDW/X3886+tk6zyQQv9Tx4sGFYY9pKFpNJXpZo29+p9MiXJ9tGtHVSP3yYdzwGgP4+3jG4vYPft6W1lcbKy8tpzLYMgK1bsJsun3DyloL39aeRSmWWpJahmN6n4RAvTe463Exj/X38WD777Fk0VlvHO5Q3tu+gsY69LTQGAJEWfv50H+Hp/u39e2ksmeDHz6Eo71LevI3vt6iH54eA4eeOSfFcFbSUibtdvAw+GrW0PbecB8byXlRUxLu+27qJA/bcGQrxJQvils7fqRRftiNuWdLj0GGej460Z54zcct7yVjTJzciIiLiKJrciIiIiKNociMiIiKOosmNiIiIOIomNyIiIuIomtyIiIiIowypFHzlypVYuXIl9u3bBwA4++yzcc8992DhwoUAjpa4feELX8CqVasQi8WwYMEC/OAHP0BlZeWQN8xlDFwms5zTWgk+3JLuYVa9Wqu9bRszSlW2rlF4jjZuSym4rZrd2t3bsp32LuzD3BbLc4hbSkT7enjZPQC4LOWc6Sxlyse0tvHSy95Ij/Ux6eOlebly0mTvan28zsVDNZa5o6qoHMFAZhdod4I/p/POOI3GDnj5MXKog5f1/sXVC2ns7HOm09jPH1lJYw17O2kMAIzh2xrr592f47waGB4v76iddvNzpN9SYmxsSz5EumjMZelunUzxsnTb3/Hefl5e7bJ0Ug9auokXFFrGPM5SIG43f1u2lYl7PB4aSyR49/pokse6Yzzn9CGz7DsOPtZYG9InN7W1tbj//vuxefNmbNq0CVdeeSWuvfZavPXWWwCAO+64A08//TSefPJJrFu3Do2NjbjhhhtGZcNF5OSh3CEiY2lIn9x89KMfHfT/b3zjG1i5ciU2bNiA2tpaPProo3jiiSdw5ZVXAgAee+wxnHnmmdiwYQMuueSSkdtqETmpKHeIyFga9m9uUqkUVq1ahUgkgrlz52Lz5s1IJBKYP3/+wG1mzJiB+vp6rF+/no4Ti8XQ3d096CIizqXcISKjbciTmzfeeAMFBQUIBAK45ZZbsHr1apx11llobm6G3+9HcXHxoNtXVlaiuZkvw718+XKEw+GBS11d3ZCfhIjkPuUOERkrQ57cTJ8+HVu3bsXGjRtx6623YvHixdi2bduwN2DZsmXo6uoauDQ08F5GInLyUu4QkbEy5MaZfr8fp59+OgBg9uzZeOWVV/Dd734Xn/jEJxCPx9HZ2TnoL7CWlhZUVVXR8QKBAAJZKhtExFmUO0RkrJxwV/B0Oo1YLIbZs2fD5/NhzZo1WLRoEQBg586dOHDgAObOnTvkcT0uA0+2kjlby2xLiZ3L+iGVpYzY8njpLKXqf76f7fGOU5dtq122Vpjbnv/wWo3bygtt5cLpJI95hrstLr4tNrbuvbB0Gi8rLqGx6tqJ1sdsaeHdm/PyeAlpX1+Exmzd1I3lWEynecfw/Pzs25JMJnGwcT+930gYrdzRFulCIJlZwlvk5edk42FetpxfzDt4zzv/DBornRCmsXXr/ofGjnTxr+Lqp9hL4490dtKYz8PLmv0F/FgveIO/TfRazi2Xx5I7Lcdy0vCS7qibH+fJFD93bO8bXnc+jeUFJ9BYOm0pkbfkRq/PR2MAkE7xfZpMWmr2rWPy/d3f00tjE4r5EgnTptZmjhWN4j+f/H9D27hRMqTJzbJly7Bw4ULU19ejp6cHTzzxBNauXYvnn38e4XAYn/vc53DnnXeitLQURUVFWLp0KebOnatqB5FTnHKHiIylIU1uWltb8dnPfhZNTU0Ih8OYOXMmnn/+eXzoQx8CADz00ENwu91YtGjRoIW4ROTUptwhImNpSJObRx991BoPBoNYsWIFVqxYcUIbJSLOotwhImNJvaVERETEUTS5EREREUc54WqpkXassoX/2txWLTWsEGBpNjf8ailbRdRoVUsNb8jhbou1WspShTTmrA03uZSlwsDWiO7ofXlVg63iwfaYtpi9Wmro1RfHHstaaZZjjm1rLJ7Z0A8AojFLk0dLc8y0pZFhpI83UO3p4U0HIxF+v6ilYavnOOeV7TmmLNVL0Rg/fmzHnT0H8JjtuLIWN9oez1pJa3l9YTnnLM0/7ec4zw/Ha5xpq5ayse1T+7bajgvLORPNrPo6duzmQt5wmVzYinc5ePCgVhoVyRENDQ2orc0s+cxFyh0iuSEX8kbOTW7S6TQaGxtRWFgIl8uF7u5u1NXVoaGhAUVFReO9eTlD+4XTvsluKPvFGIOenh7U1NTA7T45vr1+d+7o6enRMUDo/MhO+4V7v/sml/JGzn0t5Xa7s874ioqKdMBlof3Cad9k9373SzjMF6HLRe/OHce+TtYxwGnfZKf9wr2ffZMreePk+JNMRERE5H3S5EZEREQcJecnN4FAAPfee68a5L2H9gunfZPdqbRfTqXnOlTaN9lpv3An477JuR8Ui4iIiJyInP/kRkRERGQoNLkRERERR9HkRkRERBxFkxsRERFxFE1uRERExFFyenKzYsUKTJ48GcFgEHPmzMGf/vSn8d6kMffyyy/jox/9KGpqauByufCrX/1qUNwYg3vuuQfV1dUIhUKYP38+du3aNT4bO4aWL1+Oiy66CIWFhaioqMB1112HnTt3DrpNNBrFkiVLUFZWhoKCAixatAgtLS3jtMVjZ+XKlZg5c+bAaqJz587F7373u4H4qbBflDuUOxjljuycljdydnLzX//1X7jzzjtx77334tVXX8WsWbOwYMECtLa2jvemjalIJIJZs2ZhxYoVWePf/OY38b3vfQ8//OEPsXHjRuTn52PBggWIRqNjvKVja926dViyZAk2bNiAF154AYlEAldffTUikcjAbe644w48/fTTePLJJ7Fu3To0NjbihhtuGMetHhu1tbW4//77sXnzZmzatAlXXnklrr32Wrz11lsAnL9flDuOUu7ITrkjO8flDZOjLr74YrNkyZKB/6dSKVNTU2OWL18+jls1vgCY1atXD/w/nU6bqqoq8+CDDw5c19nZaQKBgPnFL34xDls4flpbWw0As27dOmPM0f3g8/nMk08+OXCb7du3GwBm/fr147WZ46akpMT8+Mc/PiX2i3JHJuUOTrmDO5nzRk5+chOPx7F582bMnz9/4Dq324358+dj/fr147hluWXv3r1obm4etJ/C4TDmzJlzyu2nrq4uAEBpaSkAYPPmzUgkEoP2zYwZM1BfX39K7ZtUKoVVq1YhEolg7ty5jt8vyh3vj3LHnyl3ZHJC3si5ruAAcPjwYaRSKVRWVg66vrKyEjt27Binrco9zc3NAJB1Px2LnQrS6TRuv/12XHrppTjnnHMAHN03fr8fxcXFg257quybN954A3PnzkU0GkVBQQFWr16Ns846C1u3bnX0flHueH+UO45S7hjMSXkjJyc3IkOxZMkSvPnmm/jDH/4w3puSM6ZPn46tW7eiq6sLTz31FBYvXox169aN92aJ5BTljsGclDdy8mupCRMmwOPxZPwSu6WlBVVVVeO0Vbnn2L44lffTbbfdhmeeeQYvvfQSamtrB66vqqpCPB5HZ2fnoNufKvvG7/fj9NNPx+zZs7F8+XLMmjUL3/3udx2/X5Q73h/lDuWObJyUN3JycuP3+zF79mysWbNm4Lp0Oo01a9Zg7ty547hluWXKlCmoqqoatJ+6u7uxceNGx+8nYwxuu+02rF69Gi+++CKmTJkyKD579mz4fL5B+2bnzp04cOCA4/dNNul0GrFYzPH7Rbnj/VHuUO54P07qvDHev2hmVq1aZQKBgHn88cfNtm3bzM0332yKi4tNc3PzeG/amOrp6TFbtmwxW7ZsMQDMt7/9bbNlyxazf/9+Y4wx999/vykuLja//vWvzeuvv26uvfZaM2XKFNPf3z/OWz66br31VhMOh83atWtNU1PTwKWvr2/gNrfccoupr683L774otm0aZOZO3eumTt37jhu9di46667zLp168zevXvN66+/bu666y7jcrnM//zP/xhjnL9flDuOUu7ITrkjO6fljZyd3BhjzMMPP2zq6+uN3+83F198sdmwYcN4b9KYe+mllwyAjMvixYuNMUdLOr/yla+YyspKEwgEzFVXXWV27tw5vhs9BrLtEwDmscceG7hNf3+/+fznP29KSkpMXl6euf76601TU9P4bfQY+fu//3szadIk4/f7TXl5ubnqqqsGEpQxp8Z+Ue5Q7mCUO7JzWt5wGWPM2H1OJCIiIjK6cvI3NyIiIiLDpcmNiIiIOIomNyIiIuIomtyIiIiIo2hyIyIiIo6iyY2IiIg4iiY3IiIi4iia3IiIiIijaHIjIiIijqLJjYiIiDiKJjciIiLiKP8/xNrX5G7mNwUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.imshow(trainX[0])\n",
        "plt.title(f\"Label: {trainY[0]}\")\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.imshow(trainX[1])\n",
        "plt.title(f\"Label: {trainY[1]}\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYyPpXH1e1uh"
      },
      "source": [
        "Question5: Build a deep learning model with atleast 4 hidden layers and more than 100 hidden neurons to classify 10 classes of CIFAR10\n",
        "\n",
        "Call this built model as **firstModel**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyQloWDfccWF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "\n",
        "firstModel = Sequential([\n",
        "    Flatten(input_shape=(32, 32, 3)),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "firstModel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-0G731ke5GA"
      },
      "source": [
        "Question6: Present model accuracy with different batches sizes & epochs. Present results as follows:\n",
        "$\n",
        " \\begin{pmatrix}\n",
        "  simulationNo & batchSize & epochs & trainingTime & trainAccuracy & testAccuracy \\\\\n",
        "  1 & 10 & 10 &   &  &  \\\\\n",
        "  2 & 10 & 100 &   &  & \\\\\n",
        "  3 & 500 & 100 &   &  \\\\\n",
        "  4 & 500 & 1000 &   &  \\\\\n",
        "  5 & \\frac{trainData size}{2} & 10 &   &  \\\\\n",
        "  6 & \\frac{trainData size}{2} & 100 &   & \\\\\n",
        "  7 & \\frac{trainData size}{2} & 500 &   & \\\\\n",
        "  8 & trainData size & 10 &   &  \\\\\n",
        "  9 & trainData size & 100 &   &  \\\\\n",
        "  10 & trainData size & 500 &   &   \n",
        " \\end{pmatrix}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPQ3VA8ChZWA",
        "outputId": "3cb1d055-1054-4617-d81d-71dd8f8e6265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4000/4000 [==============================] - 52s 13ms/step - loss: 3.2102 - accuracy: 0.0991 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 2/10\n",
            "4000/4000 [==============================] - 44s 11ms/step - loss: 2.3028 - accuracy: 0.1027 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 3/10\n",
            "4000/4000 [==============================] - 46s 11ms/step - loss: 2.3029 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 4/10\n",
            "4000/4000 [==============================] - 39s 10ms/step - loss: 2.3029 - accuracy: 0.0991 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 5/10\n",
            "4000/4000 [==============================] - 39s 10ms/step - loss: 2.3028 - accuracy: 0.0993 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 6/10\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 2.3029 - accuracy: 0.1003 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 7/10\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3028 - accuracy: 0.1027 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 8/10\n",
            "4000/4000 [==============================] - 39s 10ms/step - loss: 2.3029 - accuracy: 0.0997 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 9/10\n",
            "4000/4000 [==============================] - 39s 10ms/step - loss: 2.3029 - accuracy: 0.0976 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 10/10\n",
            "4000/4000 [==============================] - 39s 10ms/step - loss: 2.3029 - accuracy: 0.0982 - val_loss: 2.3027 - val_accuracy: 0.1000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c9c58bd7d30>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "firstModel.fit(trainX,trainY,validation_data=(testX,testY),epochs=10,batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvU_FfOuh2ap",
        "outputId": "b9eabba4-acdd-440b-da03-295b4b7d3d4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.0997 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 2/100\n",
            "4000/4000 [==============================] - 42s 10ms/step - loss: 2.3029 - accuracy: 0.0980 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 3/100\n",
            "4000/4000 [==============================] - 44s 11ms/step - loss: 2.3029 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 4/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0996 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 5/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3028 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 6/100\n",
            "4000/4000 [==============================] - 42s 11ms/step - loss: 2.3029 - accuracy: 0.0989 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 7/100\n",
            "4000/4000 [==============================] - 45s 11ms/step - loss: 2.3029 - accuracy: 0.0986 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 8/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.0995 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 9/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.1002 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 10/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0982 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 11/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 12/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0966 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 13/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 14/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 15/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.0977 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 16/100\n",
            "4000/4000 [==============================] - 43s 11ms/step - loss: 2.3029 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 17/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 18/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3028 - accuracy: 0.1005 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 19/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 20/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.0972 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 21/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.1010 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 22/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0987 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 23/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0996 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 24/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.0973 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 25/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3028 - accuracy: 0.0981 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 26/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0997 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 27/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.1003 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 28/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3028 - accuracy: 0.0998 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 29/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.1012 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 30/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.0984 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 31/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3028 - accuracy: 0.0970 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 32/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.0970 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 33/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.0992 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 34/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.1003 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 35/100\n",
            "4000/4000 [==============================] - 42s 10ms/step - loss: 2.3029 - accuracy: 0.0991 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 36/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3028 - accuracy: 0.1006 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 37/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0986 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 38/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 39/100\n",
            "4000/4000 [==============================] - 42s 11ms/step - loss: 2.3029 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 40/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3028 - accuracy: 0.0992 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 41/100\n",
            "4000/4000 [==============================] - 42s 10ms/step - loss: 2.3029 - accuracy: 0.0983 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 42/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.0998 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 43/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3028 - accuracy: 0.1019 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 44/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 45/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 46/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.0972 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 47/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.0992 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 48/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 49/100\n",
            "4000/4000 [==============================] - 42s 10ms/step - loss: 2.3029 - accuracy: 0.0968 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 50/100\n",
            "4000/4000 [==============================] - 43s 11ms/step - loss: 2.3029 - accuracy: 0.0974 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 51/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.1003 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 52/100\n",
            "4000/4000 [==============================] - 42s 11ms/step - loss: 2.3029 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 53/100\n",
            "4000/4000 [==============================] - 42s 10ms/step - loss: 2.3029 - accuracy: 0.0991 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 54/100\n",
            "4000/4000 [==============================] - 42s 11ms/step - loss: 2.3029 - accuracy: 0.1003 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 55/100\n",
            "4000/4000 [==============================] - 42s 10ms/step - loss: 2.3029 - accuracy: 0.0982 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 56/100\n",
            "4000/4000 [==============================] - 43s 11ms/step - loss: 2.3029 - accuracy: 0.0986 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 57/100\n",
            "4000/4000 [==============================] - 42s 10ms/step - loss: 2.3029 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 58/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 59/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3028 - accuracy: 0.0997 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 60/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3028 - accuracy: 0.0989 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 61/100\n",
            "4000/4000 [==============================] - 39s 10ms/step - loss: 2.3029 - accuracy: 0.0992 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 62/100\n",
            "4000/4000 [==============================] - 39s 10ms/step - loss: 2.3029 - accuracy: 0.1013 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 63/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 64/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3028 - accuracy: 0.0993 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 65/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0970 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 66/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.1011 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 67/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0972 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 68/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 69/100\n",
            "4000/4000 [==============================] - 39s 10ms/step - loss: 2.3029 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 70/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0980 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 71/100\n",
            "4000/4000 [==============================] - 39s 10ms/step - loss: 2.3028 - accuracy: 0.1009 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 72/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 73/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 74/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.1015 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 75/100\n",
            "4000/4000 [==============================] - 39s 10ms/step - loss: 2.3028 - accuracy: 0.1017 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 76/100\n",
            "4000/4000 [==============================] - 39s 10ms/step - loss: 2.3029 - accuracy: 0.1011 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 77/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0989 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 78/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0997 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 79/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3028 - accuracy: 0.0971 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 80/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3028 - accuracy: 0.1010 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 81/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 82/100\n",
            "4000/4000 [==============================] - 38s 10ms/step - loss: 2.3029 - accuracy: 0.0993 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 83/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0994 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 84/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0964 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 85/100\n",
            "4000/4000 [==============================] - 39s 10ms/step - loss: 2.3029 - accuracy: 0.1006 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 86/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0966 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 87/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0994 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 88/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.0984 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 89/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.0982 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 90/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3028 - accuracy: 0.0997 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 91/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.1007 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 92/100\n",
            "4000/4000 [==============================] - 39s 10ms/step - loss: 2.3029 - accuracy: 0.0967 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 93/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0977 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 94/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.1004 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 95/100\n",
            "4000/4000 [==============================] - 41s 10ms/step - loss: 2.3029 - accuracy: 0.1013 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 96/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.1015 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 97/100\n",
            "4000/4000 [==============================] - 42s 10ms/step - loss: 2.3029 - accuracy: 0.0952 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
            "Epoch 98/100\n",
            "4000/4000 [==============================] - 40s 10ms/step - loss: 2.3029 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 99/100\n",
            "4000/4000 [==============================] - 42s 11ms/step - loss: 2.3028 - accuracy: 0.0995 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 100/100\n",
            "4000/4000 [==============================] - 39s 10ms/step - loss: 2.3029 - accuracy: 0.0995 - val_loss: 2.3026 - val_accuracy: 0.1000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c9c58174520>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "firstModel.fit(trainX,trainY,validation_data=(testX,testY),epochs=100,batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Xb3CuEJh7a7",
        "outputId": "93916800-6691-4a6c-c7eb-18f5c67c7119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "80/80 [==============================] - 6s 63ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 2/100\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 3/100\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 4/100\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 5/100\n",
            "80/80 [==============================] - 4s 45ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 6/100\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 7/100\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 8/100\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 9/100\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 10/100\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 11/100\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 12/100\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 13/100\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 14/100\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 15/100\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 16/100\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 17/100\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 18/100\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 19/100\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 20/100\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 21/100\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 22/100\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 23/100\n",
            "80/80 [==============================] - 4s 45ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 24/100\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 25/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 26/100\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 27/100\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 28/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 29/100\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 30/100\n",
            "80/80 [==============================] - 7s 86ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 31/100\n",
            "80/80 [==============================] - 4s 46ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 32/100\n",
            "80/80 [==============================] - 4s 46ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 33/100\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 34/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 35/100\n",
            "80/80 [==============================] - 4s 46ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 36/100\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 37/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 38/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 39/100\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 40/100\n",
            "80/80 [==============================] - 4s 46ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 41/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 42/100\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 43/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 44/100\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 45/100\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 46/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 47/100\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 48/100\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 49/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 50/100\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 51/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 52/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 53/100\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 54/100\n",
            "80/80 [==============================] - 4s 47ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 55/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 56/100\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 57/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 58/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 59/100\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 60/100\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 61/100\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 62/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 63/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 64/100\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 65/100\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 66/100\n",
            "80/80 [==============================] - 4s 47ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 67/100\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 68/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1012 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 69/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 70/100\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 71/100\n",
            "80/80 [==============================] - 4s 47ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 72/100\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 73/100\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 74/100\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1003 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 75/100\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 76/100\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 77/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 78/100\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 79/100\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1006 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 80/100\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 81/100\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 82/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 83/100\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 84/100\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 85/100\n",
            "80/80 [==============================] - 4s 47ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 86/100\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 87/100\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 88/100\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 89/100\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1010 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 90/100\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 91/100\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1009 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 92/100\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 93/100\n",
            "80/80 [==============================] - 4s 47ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 94/100\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 95/100\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 96/100\n",
            "80/80 [==============================] - 4s 46ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 97/100\n",
            "80/80 [==============================] - 4s 47ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 98/100\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 99/100\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 100/100\n",
            "80/80 [==============================] - 4s 46ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c9c5c213e80>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "firstModel.fit(trainX,trainY,validation_data=(testX,testY),epochs=100,batch_size=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yMzRruNh8Fo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf13c13-6cce-41c4-de39-793ff11391a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 2/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 3/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 4/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 5/1000\n",
            "80/80 [==============================] - 4s 46ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 6/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 7/1000\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 8/1000\n",
            "80/80 [==============================] - 4s 46ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 9/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 10/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 11/1000\n",
            "80/80 [==============================] - 4s 46ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 12/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.0994 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 13/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 14/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 15/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 16/1000\n",
            "80/80 [==============================] - 4s 46ms/step - loss: 2.3026 - accuracy: 0.1003 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 17/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 18/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1003 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 19/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 20/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 21/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 22/1000\n",
            "80/80 [==============================] - 4s 46ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 23/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 24/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 25/1000\n",
            "80/80 [==============================] - 4s 47ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 26/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 27/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 28/1000\n",
            "80/80 [==============================] - 4s 47ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 29/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 30/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 31/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 32/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 33/1000\n",
            "80/80 [==============================] - 4s 46ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 34/1000\n",
            "80/80 [==============================] - 4s 47ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 35/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 36/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 37/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 38/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1007 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 39/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 40/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 41/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 42/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 43/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 44/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 45/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 46/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 47/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 48/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1009 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 49/1000\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 50/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 51/1000\n",
            "80/80 [==============================] - 4s 47ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 52/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1010 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 53/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 54/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 55/1000\n",
            "80/80 [==============================] - 4s 46ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 56/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 57/1000\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 58/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 59/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 60/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 61/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 62/1000\n",
            "80/80 [==============================] - 4s 47ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 63/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 64/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 65/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 66/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 67/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 68/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 69/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 70/1000\n",
            "80/80 [==============================] - 4s 47ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 71/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 72/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 73/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 74/1000\n",
            "80/80 [==============================] - 6s 76ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 75/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 76/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 77/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 78/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 79/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 80/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 81/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 82/1000\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 83/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 84/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 85/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 86/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 87/1000\n",
            "80/80 [==============================] - 4s 47ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 88/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 89/1000\n",
            "80/80 [==============================] - 4s 47ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 90/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 91/1000\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 92/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.0998 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 93/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 94/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 95/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 96/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 97/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 98/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 99/1000\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 100/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 101/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 102/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 103/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 104/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 105/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 106/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 107/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 108/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 109/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1009 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 110/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1002 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 111/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 112/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 113/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 114/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 115/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 116/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 117/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 118/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 119/1000\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 120/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 121/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 122/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1005 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 123/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 124/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 125/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 126/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 127/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 128/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 129/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 130/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.0990 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 131/1000\n",
            "80/80 [==============================] - 4s 47ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 132/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 133/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 134/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 135/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 136/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 137/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 138/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 139/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 140/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 141/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 142/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 143/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 144/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 145/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1007 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 146/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 147/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 148/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 149/1000\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 150/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 151/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 152/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 153/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 154/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 155/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1005 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 156/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 157/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 158/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 159/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 160/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 161/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 162/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 163/1000\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 164/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 165/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 166/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 167/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1005 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 168/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 169/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 170/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 171/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 172/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 173/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 174/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 175/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 176/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 177/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 178/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 179/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 180/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 181/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 182/1000\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 2.3026 - accuracy: 0.1011 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 183/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 184/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 185/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 186/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 187/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 188/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 189/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 190/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 191/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 192/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 193/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1002 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 194/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 195/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 196/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 197/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 198/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 199/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 200/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 201/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 202/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 203/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1007 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 204/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 205/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.0998 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 206/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 207/1000\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 208/1000\n",
            "80/80 [==============================] - 4s 47ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 209/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 210/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 211/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 212/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 213/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 214/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 215/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 216/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 217/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 218/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 219/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 220/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 221/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1010 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 222/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 223/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 224/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 225/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 226/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 227/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 228/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 229/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 230/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 231/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 232/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 233/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 234/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 235/1000\n",
            "80/80 [==============================] - 5s 66ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 236/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 237/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 238/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 239/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.0998 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 240/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 241/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 242/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 243/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 244/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 245/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 246/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 247/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 248/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 249/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 250/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 251/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 252/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 253/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 254/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 255/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 256/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 257/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 258/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 259/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 260/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1012 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 261/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 262/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 263/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 264/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1005 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 265/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 266/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 267/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 268/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 269/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 270/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 271/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 272/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 273/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 274/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 275/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 276/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 277/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 278/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 279/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 280/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 281/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 282/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 283/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 284/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 285/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 286/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 287/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 288/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 289/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 290/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 291/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 292/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 293/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 294/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 295/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 296/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 297/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 298/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 299/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 300/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 301/1000\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 302/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 303/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 304/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 305/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 306/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 307/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 308/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 309/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 310/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 311/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 312/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1002 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 313/1000\n",
            "80/80 [==============================] - 4s 48ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 314/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 315/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 316/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 317/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 318/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 319/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 320/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 321/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1002 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 322/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 323/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 324/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 325/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 326/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 327/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 328/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 329/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 330/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 331/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 332/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 333/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 334/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1005 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 335/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 336/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 337/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 338/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 339/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 340/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 341/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 342/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 343/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 344/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 345/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 346/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 347/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 348/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 349/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 350/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 351/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 352/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 353/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 354/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 355/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 356/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 357/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 358/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 359/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 360/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 361/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 362/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 363/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 364/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1007 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 365/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 366/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 367/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 368/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 369/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 370/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 371/1000\n",
            "80/80 [==============================] - 4s 49ms/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 372/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 373/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 374/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 375/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 376/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 377/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 378/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 379/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 380/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 381/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 382/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 383/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 384/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 385/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 386/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1010 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 387/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 388/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 389/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 390/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 391/1000\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 392/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 393/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1005 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 394/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 395/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 396/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 397/1000\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 398/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.0998 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 399/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 400/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 401/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 402/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 403/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 404/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 405/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 406/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 407/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 408/1000\n",
            "80/80 [==============================] - 5s 66ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 409/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 410/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 411/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 412/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 413/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 414/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1007 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 415/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 416/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 417/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 418/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 419/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 420/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 421/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 422/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 423/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 424/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 425/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 426/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 427/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 428/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 429/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 430/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 431/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 432/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 433/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 434/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 435/1000\n",
            "80/80 [==============================] - 5s 66ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 436/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 437/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 438/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 439/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1006 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 440/1000\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 441/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.0994 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 442/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 443/1000\n",
            "80/80 [==============================] - 5s 66ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 444/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 445/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 446/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 447/1000\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 448/1000\n",
            "80/80 [==============================] - 5s 66ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 449/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 450/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 451/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 452/1000\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 453/1000\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 454/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 455/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 456/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 457/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 458/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 459/1000\n",
            "80/80 [==============================] - 5s 66ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 460/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 461/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 462/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 463/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 464/1000\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 465/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 466/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 467/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 468/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 469/1000\n",
            "80/80 [==============================] - 5s 66ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 470/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 471/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 472/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 473/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 474/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 475/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 476/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 477/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 478/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 479/1000\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 480/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 481/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 482/1000\n",
            "80/80 [==============================] - 5s 68ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 483/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 484/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 485/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 486/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 487/1000\n",
            "80/80 [==============================] - 5s 69ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 488/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 489/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 490/1000\n",
            "80/80 [==============================] - 5s 66ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 491/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 492/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 493/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 494/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 495/1000\n",
            "80/80 [==============================] - 5s 68ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 496/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 497/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 498/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 499/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 500/1000\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 2.3026 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 501/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 502/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 503/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 504/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 505/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 506/1000\n",
            "80/80 [==============================] - 5s 68ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 507/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 508/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 509/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 510/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 511/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 512/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 513/1000\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 514/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 515/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 516/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 517/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 518/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 519/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 520/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 521/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 522/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 523/1000\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 524/1000\n",
            "80/80 [==============================] - 5s 68ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 525/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 526/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 527/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1006 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 528/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 529/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 530/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 531/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 532/1000\n",
            "80/80 [==============================] - 5s 66ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 533/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 534/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 535/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 536/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 537/1000\n",
            "80/80 [==============================] - 5s 68ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 538/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 539/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 540/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 541/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 542/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 543/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 544/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 545/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 546/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 547/1000\n",
            "80/80 [==============================] - 5s 68ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 548/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 549/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 550/1000\n",
            "80/80 [==============================] - 5s 68ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 551/1000\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 552/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 553/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 554/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 555/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 556/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 557/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 558/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 559/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 560/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 561/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 562/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 563/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 564/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 565/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 566/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 567/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 568/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 569/1000\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 570/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 571/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 572/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 573/1000\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 574/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 575/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 576/1000\n",
            "80/80 [==============================] - 5s 68ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 577/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 578/1000\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 579/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 580/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1009 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 581/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 582/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 583/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 584/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 585/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 586/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 587/1000\n",
            "80/80 [==============================] - 5s 69ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 588/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 589/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 590/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 591/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 592/1000\n",
            "80/80 [==============================] - 5s 68ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 593/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 594/1000\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 595/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 596/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 597/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 598/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 599/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 600/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 601/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 602/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 603/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1008 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 604/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 605/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 606/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 607/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 608/1000\n",
            "80/80 [==============================] - 5s 68ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 609/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 610/1000\n",
            "80/80 [==============================] - 4s 52ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 611/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 612/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 613/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 614/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 615/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 616/1000\n",
            "80/80 [==============================] - 5s 68ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 617/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 618/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 619/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 620/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 621/1000\n",
            "80/80 [==============================] - 5s 66ms/step - loss: 2.3026 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 622/1000\n",
            "80/80 [==============================] - 4s 53ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 623/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 624/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 625/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 626/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 627/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 628/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 629/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 630/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 631/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 632/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 633/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 634/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 635/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 636/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 637/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 638/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 639/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 640/1000\n",
            "80/80 [==============================] - 5s 63ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 641/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 642/1000\n",
            "80/80 [==============================] - 5s 68ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 643/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 644/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 645/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 646/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 647/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 648/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 649/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 650/1000\n",
            "80/80 [==============================] - 5s 68ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 651/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 652/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 653/1000\n",
            "80/80 [==============================] - 5s 64ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 654/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 655/1000\n",
            "80/80 [==============================] - 5s 68ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 656/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 657/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 658/1000\n",
            "80/80 [==============================] - 6s 71ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 659/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 660/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 661/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 662/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 663/1000\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 2.3026 - accuracy: 0.1005 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 664/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 665/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 666/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 667/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 668/1000\n",
            "80/80 [==============================] - 5s 69ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 669/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 670/1000\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 671/1000\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 672/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 673/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1012 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 674/1000\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 675/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 676/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 677/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 678/1000\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 679/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 680/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 681/1000\n",
            "80/80 [==============================] - 5s 66ms/step - loss: 2.3026 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 682/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 683/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 684/1000\n",
            "80/80 [==============================] - 5s 62ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 685/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 686/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 687/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 688/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 689/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 690/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 691/1000\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 692/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 693/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 694/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 695/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 696/1000\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 697/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 698/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 699/1000\n",
            "80/80 [==============================] - 6s 69ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 700/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 701/1000\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 702/1000\n",
            "80/80 [==============================] - 5s 59ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 703/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 704/1000\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 705/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 706/1000\n",
            "80/80 [==============================] - 5s 66ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 707/1000\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 708/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 709/1000\n",
            "80/80 [==============================] - 5s 66ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 710/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 711/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 712/1000\n",
            "80/80 [==============================] - 5s 58ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 713/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 714/1000\n",
            "80/80 [==============================] - 5s 68ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 715/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 716/1000\n",
            "80/80 [==============================] - 5s 65ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 717/1000\n",
            "80/80 [==============================] - 5s 61ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 718/1000\n",
            "80/80 [==============================] - 5s 60ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 719/1000\n",
            "80/80 [==============================] - 6s 70ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 720/1000\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 2.3026 - accuracy: 0.1017 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 721/1000\n",
            " 8/80 [==>...........................] - ETA: 3s - loss: 2.3024 - accuracy: 0.1138"
          ]
        }
      ],
      "source": [
        "firstModel.fit(trainX,trainY,validation_data=(testX,testY),epochs=1000,batch_size=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKov_7PQh871"
      },
      "outputs": [],
      "source": [
        "firstModel.fit(trainX,trainY,validation_data=(testX,testY),epochs=10,batch_size=20000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rKiAl3Eh98S"
      },
      "outputs": [],
      "source": [
        "firstModel.fit(trainX,trainY,validation_data=(testX,testY),epochs=100,batch_size=20000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6UJEISHh-vr"
      },
      "outputs": [],
      "source": [
        "firstModel.fit(trainX,trainY,validation_data=(testX,testY),epochs=500,batch_size=20000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqS6dJCyh_ub"
      },
      "outputs": [],
      "source": [
        "firstModel.fit(trainX,trainY,validation_data=(testX,testY),epochs=10,batch_size=40000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlWmiM3KiAbm"
      },
      "outputs": [],
      "source": [
        "firstModel.fit(trainX,trainY,validation_data=(testX,testY),epochs=100,batch_size=40000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yj4nqZHLl-V5"
      },
      "outputs": [],
      "source": [
        "firstModel.fit(trainX,trainY,validation_data=(testX,testY),epochs=500,batch_size=40000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ypk5mOLofCeq"
      },
      "source": [
        "Question7: Plot testY[0] and testY[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "dfSX_aTQcssU",
        "outputId": "5aa104ec-cd03-45a2-c6e6-8d70a95cf864"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.subplot(121)\n",
        "plt.imshow(testX[0])\n",
        "plt.title(f\"Label: {testY[0]}\")\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.imshow(testX[1])\n",
        "plt.title(f\"Label: {testY[1]}\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it1xy-3Rayoh"
      },
      "source": [
        "Question8: Predict testY[0] and testY[1] class using **firstModel**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkK6V3GMcv5L",
        "outputId": "359689ec-1b8a-4f39-8742-b92365ed214d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = firstModel.predict(testX[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPFTnZ3hhpwA",
        "outputId": "8bf56af8-70e0-4b5b-9f9b-905288fbe6ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted class for testY[0]: 7\n",
            "Predicted class for testY[1]: 7\n"
          ]
        }
      ],
      "source": [
        "print(\"Predicted class for testY[0]:\", predicted_labels[0])\n",
        "print(\"Predicted class for testY[1]:\", predicted_labels[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLn4udarfTEU"
      },
      "source": [
        "Question9: Compare prediction results with actual test images (refer to Question 7 for actual test images). Write down your observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft_2jiIsc145",
        "outputId": "ca64d74e-87a4-4f05-c162-30bc07101eb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Labels: [7, 7]\n",
            "Actual Labels: [3, 8]\n"
          ]
        }
      ],
      "source": [
        "predicted_labels = [tf.argmax(pred).numpy() for pred in predictions]\n",
        "actual_labels = [tf.argmax(actual).numpy() for actual in testY[:2]]\n",
        "\n",
        "print(\"Predicted Labels:\", predicted_labels)\n",
        "print(\"Actual Labels:\", actual_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNHuUwSUfjqz"
      },
      "source": [
        "Question10: Save your jupyter notebook(with your simulation results) and send to Arabinda Panda by email"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}